{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98924e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f82925",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweet = pd.read_csv (r\"C:\\Users\\vira_\\Downloads\\tweet_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3cb1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad229db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweet[\"sentiment\"] = data_tweet[\"sentiment\"].apply(lambda x: x if x in ['neutral', 'worry', 'happiness', 'sadness', 'love'] \n",
    "                                               else 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf1ce0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8241d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90a8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    text = re.sub(r'\\W', ' ', str(text))\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemma_text = [stemmer.lemmatize(word) for word in tokens]\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    no_stop_text = [word for word in lemma_text if word not in stops] \n",
    "    clean_text = ' '.join(no_stop_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f971fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweet['content'] = data_tweet['content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa17cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tweet.drop(['tweet_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4344a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweets_tokens = [tweet_tokenizer.tokenize(x) for x in data_tweet['content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269221b8",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d58511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bf33d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data_tweet['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef87639",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_tweet[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab4900",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc84fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=data_tweet.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbf39bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "neutral      6094\n",
      "other        6006\n",
      "worry        5995\n",
      "happiness    3619\n",
      "sadness      3605\n",
      "love         2681\n",
      "Name: sentiment, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "other        2681\n",
      "neutral      2544\n",
      "worry        2464\n",
      "happiness    1590\n",
      "sadness      1560\n",
      "love         1161\n",
      "Name: sentiment, dtype: int64\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(data_tweet, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(y_train))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_train_test(data_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378c74c",
   "metadata": {},
   "source": [
    "### Исправление дисбаланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72215131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e779aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b6294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d050b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (36564, 45660)\n",
      "After OverSampling, the shape of train_y: (36564,) \n",
      "\n",
      "After OverSampling, counts of label 'neutral': 6094\n",
      "After OverSampling, counts of label 'other': 6094 \n",
      "\n",
      "After OverSampling, counts of label 'worry': 6094\n",
      "After OverSampling, counts of label 'happiness': 6094 \n",
      "\n",
      "After OverSampling, counts of label 'sadness': 6094\n",
      "After OverSampling, counts of label 'love': 6094 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "\n",
    "\n",
    "print(\"After OverSampling, counts of label 'neutral': {}\".format(sum(y_train_res == 'neutral')))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'other': {} \\n\".format(sum(y_train_res == 'other')))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'worry': {}\".format(sum(y_train_res == 'worry')))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'happiness': {} \\n\".format(sum(y_train_res == 'happiness')))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'sadness': {}\".format(sum(y_train_res == 'sadness')))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'love': {} \\n\".format(sum(y_train_res == 'love')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8643f",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad48eefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.36      0.11      0.17      1590\n",
      "        love       0.57      0.22      0.31      1161\n",
      "     neutral       0.36      0.25      0.29      2544\n",
      "       other       0.28      0.43      0.34      2681\n",
      "     sadness       0.47      0.05      0.10      1560\n",
      "       worry       0.30      0.61      0.40      2464\n",
      "\n",
      "    accuracy                           0.32     12000\n",
      "   macro avg       0.39      0.28      0.27     12000\n",
      "weighted avg       0.36      0.32      0.29     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # на дисбалансе классов\n",
    "from sklearn.metrics import classification_report\n",
    "clf = MultinomialNB(alpha = 2.2).fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "# print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df82b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "234cfd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>387</td>\n",
       "      <td>176</td>\n",
       "      <td>154</td>\n",
       "      <td>538</td>\n",
       "      <td>36</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>168</td>\n",
       "      <td>412</td>\n",
       "      <td>77</td>\n",
       "      <td>275</td>\n",
       "      <td>36</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>244</td>\n",
       "      <td>161</td>\n",
       "      <td>473</td>\n",
       "      <td>664</td>\n",
       "      <td>159</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>243</td>\n",
       "      <td>136</td>\n",
       "      <td>283</td>\n",
       "      <td>959</td>\n",
       "      <td>145</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>347</td>\n",
       "      <td>296</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>112</td>\n",
       "      <td>85</td>\n",
       "      <td>215</td>\n",
       "      <td>497</td>\n",
       "      <td>218</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  387             176                154   \n",
       "Actual love                       168             412                 77   \n",
       "Actual neutral                    244             161                473   \n",
       "Actual other                      243             136                283   \n",
       "Actual sadness                     47              45                 98   \n",
       "Actual worry                      112              85                215   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              538                 36              299  \n",
       "Actual love                   275                 36              193  \n",
       "Actual neutral                664                159              843  \n",
       "Actual other                  959                145              915  \n",
       "Actual sadness                347                296              727  \n",
       "Actual worry                  497                218             1337  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06a3e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94454db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_train = clf.predict(X_train)\n",
    "y_valid1 = y_test.values.reshape(-1,1)\n",
    "y_valid_train1 = y_train.values.reshape(-1,1)\n",
    "ypred1 = y_predicted.reshape(-1,1)\n",
    "ypred_train1 = y_predicted_train.reshape(-1,1)\n",
    "y_valid1 = pd.DataFrame(y_test)\n",
    "y_valid_train1 = pd.DataFrame(y_train)\n",
    "ypred1 = pd.DataFrame(y_predicted)\n",
    "ypred_train1 = pd.DataFrame(y_predicted_train)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid1 = onehotencoder.fit_transform(y_valid1).toarray()\n",
    "y_valid_train1 = onehotencoder.fit_transform(y_valid_train1).toarray()\n",
    "ypred1 = onehotencoder.fit_transform(ypred1).toarray()\n",
    "ypred_train1 = onehotencoder.fit_transform(ypred_train1).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1595df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9601cf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.41729039574945"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid1, ypred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb582655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.32      0.24      0.28      1590\n",
      "        love       0.41      0.35      0.38      1161\n",
      "     neutral       0.36      0.19      0.25      2544\n",
      "       other       0.29      0.36      0.32      2681\n",
      "     sadness       0.33      0.19      0.24      1560\n",
      "       worry       0.31      0.54      0.39      2464\n",
      "\n",
      "    accuracy                           0.32     12000\n",
      "   macro avg       0.34      0.31      0.31     12000\n",
      "weighted avg       0.33      0.32      0.31     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # сбалансированные классы\n",
    "from sklearn.metrics import classification_report\n",
    "clf = MultinomialNB(alpha = 2.2).fit(X_train_res, y_train_res)\n",
    "y_predicted1 = clf.predict(X_test)\n",
    "# print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, y_predicted))\n",
    "print(classification_report(y_test, y_predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8319ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>387</td>\n",
       "      <td>176</td>\n",
       "      <td>154</td>\n",
       "      <td>538</td>\n",
       "      <td>36</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>168</td>\n",
       "      <td>412</td>\n",
       "      <td>77</td>\n",
       "      <td>275</td>\n",
       "      <td>36</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>244</td>\n",
       "      <td>161</td>\n",
       "      <td>473</td>\n",
       "      <td>664</td>\n",
       "      <td>159</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>243</td>\n",
       "      <td>136</td>\n",
       "      <td>283</td>\n",
       "      <td>959</td>\n",
       "      <td>145</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>347</td>\n",
       "      <td>296</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>112</td>\n",
       "      <td>85</td>\n",
       "      <td>215</td>\n",
       "      <td>497</td>\n",
       "      <td>218</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  387             176                154   \n",
       "Actual love                       168             412                 77   \n",
       "Actual neutral                    244             161                473   \n",
       "Actual other                      243             136                283   \n",
       "Actual sadness                     47              45                 98   \n",
       "Actual worry                      112              85                215   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              538                 36              299  \n",
       "Actual love                   275                 36              193  \n",
       "Actual neutral                664                159              843  \n",
       "Actual other                  959                145              915  \n",
       "Actual sadness                347                296              727  \n",
       "Actual worry                  497                218             1337  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, y_predicted1)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef369a",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a705387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef0f5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier().fit(X_train, y_train) # на дисбалансе классов\n",
    "tree_y_pred = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "299919b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.26      0.24      0.25      1590\n",
      "        love       0.36      0.35      0.36      1161\n",
      "     neutral       0.33      0.42      0.37      2544\n",
      "       other       0.28      0.25      0.27      2681\n",
      "     sadness       0.28      0.23      0.25      1560\n",
      "       worry       0.28      0.29      0.28      2464\n",
      "\n",
      "    accuracy                           0.30     12000\n",
      "   macro avg       0.30      0.30      0.30     12000\n",
      "weighted avg       0.30      0.30      0.30     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ad126b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>445</td>\n",
       "      <td>352</td>\n",
       "      <td>204</td>\n",
       "      <td>240</td>\n",
       "      <td>186</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>225</td>\n",
       "      <td>507</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>489</td>\n",
       "      <td>367</td>\n",
       "      <td>442</td>\n",
       "      <td>275</td>\n",
       "      <td>653</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>546</td>\n",
       "      <td>381</td>\n",
       "      <td>372</td>\n",
       "      <td>378</td>\n",
       "      <td>635</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>167</td>\n",
       "      <td>146</td>\n",
       "      <td>189</td>\n",
       "      <td>170</td>\n",
       "      <td>609</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>350</td>\n",
       "      <td>293</td>\n",
       "      <td>323</td>\n",
       "      <td>292</td>\n",
       "      <td>729</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  445             352                204   \n",
       "Actual love                       225             507                107   \n",
       "Actual neutral                    489             367                442   \n",
       "Actual other                      546             381                372   \n",
       "Actual sadness                    167             146                189   \n",
       "Actual worry                      350             293                323   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              240                186              163  \n",
       "Actual love                   117                118               87  \n",
       "Actual neutral                275                653              318  \n",
       "Actual other                  378                635              369  \n",
       "Actual sadness                170                609              279  \n",
       "Actual worry                  292                729              477  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, tree_y_pred)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f06cbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_y_pred_train = tree_clf.predict(X_train)\n",
    "y_valid2 = y_test.values.reshape(-1,1)\n",
    "y_valid_train2 = y_train.values.reshape(-1,1)\n",
    "ypred2 = tree_y_pred.reshape(-1,1)\n",
    "ypred_train2 = tree_y_pred_train.reshape(-1,1)\n",
    "y_valid2 = pd.DataFrame(y_test)\n",
    "y_valid_train2 = pd.DataFrame(y_train)\n",
    "ypred2 = pd.DataFrame(tree_y_pred)\n",
    "ypred_train2 = pd.DataFrame(tree_y_pred_train)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid2 = onehotencoder.fit_transform(y_valid2).toarray()\n",
    "y_valid_train2 = onehotencoder.fit_transform(y_valid_train2).toarray()\n",
    "ypred2 = onehotencoder.fit_transform(ypred2).toarray()\n",
    "ypred_train2 = onehotencoder.fit_transform(ypred_train2).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df2550b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.312791150189472"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid2, ypred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17c8b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier().fit(X_train_res, y_train_res) # сбалансированные классы\n",
    "tree_y_pred1 = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de8e114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.21      0.30      0.25      1590\n",
      "        love       0.25      0.44      0.32      1161\n",
      "     neutral       0.26      0.17      0.21      2544\n",
      "       other       0.26      0.14      0.19      2681\n",
      "     sadness       0.21      0.39      0.27      1560\n",
      "       worry       0.27      0.18      0.22      2464\n",
      "\n",
      "    accuracy                           0.24     12000\n",
      "   macro avg       0.24      0.27      0.24     12000\n",
      "weighted avg       0.25      0.24      0.23     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_y_pred1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddff128a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>471</td>\n",
       "      <td>355</td>\n",
       "      <td>207</td>\n",
       "      <td>224</td>\n",
       "      <td>171</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>215</td>\n",
       "      <td>516</td>\n",
       "      <td>102</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>488</td>\n",
       "      <td>373</td>\n",
       "      <td>429</td>\n",
       "      <td>288</td>\n",
       "      <td>658</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>542</td>\n",
       "      <td>368</td>\n",
       "      <td>383</td>\n",
       "      <td>388</td>\n",
       "      <td>628</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>164</td>\n",
       "      <td>147</td>\n",
       "      <td>179</td>\n",
       "      <td>188</td>\n",
       "      <td>606</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>327</td>\n",
       "      <td>303</td>\n",
       "      <td>739</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  471             355                207   \n",
       "Actual love                       215             516                102   \n",
       "Actual neutral                    488             373                429   \n",
       "Actual other                      542             368                383   \n",
       "Actual sadness                    164             147                179   \n",
       "Actual worry                      345             296                327   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              224                171              162  \n",
       "Actual love                   120                121               87  \n",
       "Actual neutral                288                658              308  \n",
       "Actual other                  388                628              372  \n",
       "Actual sadness                188                606              276  \n",
       "Actual worry                  303                739              454  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, tree_y_pred1)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326d813",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62d9bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3c11dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.54      0.00      0.01      1590\n",
      "        love       0.63      0.06      0.11      1161\n",
      "     neutral       0.28      0.74      0.41      2544\n",
      "       other       0.29      0.26      0.27      2681\n",
      "     sadness       0.00      0.00      0.00      1560\n",
      "       worry       0.33      0.37      0.35      2464\n",
      "\n",
      "    accuracy                           0.30     12000\n",
      "   macro avg       0.35      0.24      0.19     12000\n",
      "weighted avg       0.32      0.30      0.23     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20) # на дисбалансе классов\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a47de9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>476</td>\n",
       "      <td>240</td>\n",
       "      <td>261</td>\n",
       "      <td>242</td>\n",
       "      <td>167</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>195</td>\n",
       "      <td>549</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>257</td>\n",
       "      <td>146</td>\n",
       "      <td>741</td>\n",
       "      <td>275</td>\n",
       "      <td>670</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>358</td>\n",
       "      <td>198</td>\n",
       "      <td>518</td>\n",
       "      <td>488</td>\n",
       "      <td>575</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>211</td>\n",
       "      <td>160</td>\n",
       "      <td>591</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>159</td>\n",
       "      <td>134</td>\n",
       "      <td>411</td>\n",
       "      <td>292</td>\n",
       "      <td>609</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  476             240                261   \n",
       "Actual love                       195             549                110   \n",
       "Actual neutral                    257             146                741   \n",
       "Actual other                      358             198                518   \n",
       "Actual sadness                     80              91                211   \n",
       "Actual worry                      159             134                411   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              242                167              204  \n",
       "Actual love                    96                118               93  \n",
       "Actual neutral                275                670              455  \n",
       "Actual other                  488                575              544  \n",
       "Actual sadness                160                591              427  \n",
       "Actual worry                  292                609              859  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, preds)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6815d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = rf.predict(X_train)\n",
    "y_valid3 = y_test.values.reshape(-1,1)\n",
    "y_valid_train3 = y_train.values.reshape(-1,1)\n",
    "ypred3 = preds.reshape(-1,1)\n",
    "ypred_train3 = preds_train.reshape(-1,1)\n",
    "y_valid3 = pd.DataFrame(y_test)\n",
    "y_valid_train3 = pd.DataFrame(y_train)\n",
    "ypred3 = pd.DataFrame(preds)\n",
    "ypred_train3 = pd.DataFrame(preds_train)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid3 = onehotencoder.fit_transform(y_valid3).toarray()\n",
    "y_valid_train3 = onehotencoder.fit_transform(y_valid_train3).toarray()\n",
    "ypred3 = onehotencoder.fit_transform(ypred3).toarray()\n",
    "ypred_train3 = onehotencoder.fit_transform(ypred_train3).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb1504a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.877807414348265"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid3, ypred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9df3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.29      0.33      0.31      1590\n",
      "        love       0.41      0.48      0.44      1161\n",
      "     neutral       0.32      0.25      0.28      2544\n",
      "       other       0.31      0.17      0.22      2681\n",
      "     sadness       0.21      0.37      0.27      1560\n",
      "       worry       0.33      0.35      0.34      2464\n",
      "\n",
      "    accuracy                           0.30     12000\n",
      "   macro avg       0.31      0.33      0.31     12000\n",
      "weighted avg       0.31      0.30      0.30     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=20) # сбалансированные классы\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "preds1 = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "968483b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>524</td>\n",
       "      <td>235</td>\n",
       "      <td>244</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>220</td>\n",
       "      <td>552</td>\n",
       "      <td>101</td>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>338</td>\n",
       "      <td>152</td>\n",
       "      <td>646</td>\n",
       "      <td>267</td>\n",
       "      <td>665</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>431</td>\n",
       "      <td>196</td>\n",
       "      <td>473</td>\n",
       "      <td>465</td>\n",
       "      <td>579</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>582</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>197</td>\n",
       "      <td>127</td>\n",
       "      <td>362</td>\n",
       "      <td>293</td>\n",
       "      <td>613</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  524             235                244   \n",
       "Actual love                       220             552                101   \n",
       "Actual neutral                    338             152                646   \n",
       "Actual other                      431             196                473   \n",
       "Actual sadness                    100              89                176   \n",
       "Actual worry                      197             127                362   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              191                192              204  \n",
       "Actual love                    78                116               94  \n",
       "Actual neutral                267                665              476  \n",
       "Actual other                  465                579              537  \n",
       "Actual sadness                190                582              423  \n",
       "Actual worry                  293                613              872  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, preds1)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6601f",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1da9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d367d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train) # на дисбалансе классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba5b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.24      0.35      0.28      1074\n",
      "        love       0.36      0.54      0.43       773\n",
      "     neutral       0.53      0.36      0.43      3820\n",
      "       other       0.35      0.32      0.33      2987\n",
      "     sadness       0.17      0.43      0.24       607\n",
      "       worry       0.39      0.35      0.37      2739\n",
      "\n",
      "    accuracy                           0.36     12000\n",
      "   macro avg       0.34      0.39      0.35     12000\n",
      "weighted avg       0.40      0.36      0.37     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_svm = model.predict(X_test)\n",
    "print(classification_report(pred_svm, y_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "392c32ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>429</td>\n",
       "      <td>133</td>\n",
       "      <td>250</td>\n",
       "      <td>523</td>\n",
       "      <td>68</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>168</td>\n",
       "      <td>377</td>\n",
       "      <td>133</td>\n",
       "      <td>322</td>\n",
       "      <td>64</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>372</td>\n",
       "      <td>95</td>\n",
       "      <td>699</td>\n",
       "      <td>534</td>\n",
       "      <td>423</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>299</td>\n",
       "      <td>118</td>\n",
       "      <td>465</td>\n",
       "      <td>938</td>\n",
       "      <td>324</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>194</td>\n",
       "      <td>337</td>\n",
       "      <td>410</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>158</td>\n",
       "      <td>71</td>\n",
       "      <td>387</td>\n",
       "      <td>515</td>\n",
       "      <td>448</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  429             133                250   \n",
       "Actual love                       168             377                133   \n",
       "Actual neutral                    372              95                699   \n",
       "Actual other                      299             118                465   \n",
       "Actual sadness                     68              49                194   \n",
       "Actual worry                      158              71                387   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              523                 68              187  \n",
       "Actual love                   322                 64               97  \n",
       "Actual neutral                534                423              421  \n",
       "Actual other                  938                324              537  \n",
       "Actual sadness                337                410              502  \n",
       "Actual worry                  515                448              885  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, pred_svm)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "120e731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_train = model.predict(X_train)\n",
    "y_valid4 = y_test.values.reshape(-1,1)\n",
    "y_valid_train4 = y_train.values.reshape(-1,1)\n",
    "ypred4 = pred_svm.reshape(-1,1)\n",
    "ypred_train4 = pred_svm_train.reshape(-1,1)\n",
    "y_valid4 = pd.DataFrame(y_test)\n",
    "y_valid_train4 = pd.DataFrame(y_train)\n",
    "ypred4 = pd.DataFrame(pred_svm)\n",
    "ypred_train4 = pd.DataFrame(pred_svm_train)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid4 = onehotencoder.fit_transform(y_valid4).toarray()\n",
    "y_valid_train4 = onehotencoder.fit_transform(y_valid_train4).toarray()\n",
    "ypred4 = onehotencoder.fit_transform(ypred4).toarray()\n",
    "ypred_train4 = onehotencoder.fit_transform(ypred_train4).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred4.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01e0ac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.77994754789602"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid4, ypred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913224e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_res, y_train_res) # сбалансированные классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98bf2526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.27      0.29      0.28      1494\n",
      "        love       0.32      0.45      0.38       843\n",
      "     neutral       0.27      0.33      0.30      2128\n",
      "       other       0.35      0.30      0.32      3169\n",
      "     sadness       0.26      0.24      0.25      1737\n",
      "       worry       0.36      0.34      0.35      2629\n",
      "\n",
      "    accuracy                           0.31     12000\n",
      "   macro avg       0.31      0.32      0.31     12000\n",
      "weighted avg       0.31      0.31      0.31     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_svm1 = model.predict(X_test)\n",
    "print(classification_report(pred_svm1, y_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dc6e1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>429</td>\n",
       "      <td>133</td>\n",
       "      <td>250</td>\n",
       "      <td>523</td>\n",
       "      <td>68</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>168</td>\n",
       "      <td>377</td>\n",
       "      <td>133</td>\n",
       "      <td>322</td>\n",
       "      <td>64</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>372</td>\n",
       "      <td>95</td>\n",
       "      <td>699</td>\n",
       "      <td>534</td>\n",
       "      <td>423</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>299</td>\n",
       "      <td>118</td>\n",
       "      <td>465</td>\n",
       "      <td>938</td>\n",
       "      <td>324</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>194</td>\n",
       "      <td>337</td>\n",
       "      <td>410</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>158</td>\n",
       "      <td>71</td>\n",
       "      <td>387</td>\n",
       "      <td>515</td>\n",
       "      <td>448</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  429             133                250   \n",
       "Actual love                       168             377                133   \n",
       "Actual neutral                    372              95                699   \n",
       "Actual other                      299             118                465   \n",
       "Actual sadness                     68              49                194   \n",
       "Actual worry                      158              71                387   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              523                 68              187  \n",
       "Actual love                   322                 64               97  \n",
       "Actual neutral                534                423              421  \n",
       "Actual other                  938                324              537  \n",
       "Actual sadness                337                410              502  \n",
       "Actual worry                  515                448              885  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, pred_svm1)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701c75e",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7a6f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98f177fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41e14123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.7245           13.49m\n",
      "         2           1.7110           12.99m\n",
      "         3           1.7008           12.70m\n",
      "         4           1.6922           12.55m\n",
      "         5           1.6855           12.41m\n",
      "         6           1.6795           12.23m\n",
      "         7           1.6741           12.09m\n",
      "         8           1.6696           11.95m\n",
      "         9           1.6653           11.80m\n",
      "        10           1.6616           11.66m\n",
      "        11           1.6580           11.55m\n",
      "        12           1.6547           11.44m\n",
      "        13           1.6515           11.30m\n",
      "        14           1.6486           11.17m\n",
      "        15           1.6459           11.05m\n",
      "        16           1.6432           10.91m\n",
      "        17           1.6409           10.78m\n",
      "        18           1.6387           10.64m\n",
      "        19           1.6362           10.51m\n",
      "        20           1.6339           10.38m\n",
      "        21           1.6318           10.26m\n",
      "        22           1.6298           10.12m\n",
      "        23           1.6273           10.01m\n",
      "        24           1.6252            9.87m\n",
      "        25           1.6233            9.74m\n",
      "        26           1.6212            9.60m\n",
      "        27           1.6193            9.47m\n",
      "        28           1.6176            9.34m\n",
      "        29           1.6158            9.21m\n",
      "        30           1.6138            9.10m\n",
      "        31           1.6122            8.98m\n",
      "        32           1.6105            8.86m\n",
      "        33           1.6088            8.73m\n",
      "        34           1.6071            8.60m\n",
      "        35           1.6055            8.46m\n",
      "        36           1.6039            8.33m\n",
      "        37           1.6023            8.20m\n",
      "        38           1.6004            8.07m\n",
      "        39           1.5990            7.94m\n",
      "        40           1.5976            7.80m\n",
      "        41           1.5960            7.67m\n",
      "        42           1.5948            7.54m\n",
      "        43           1.5931            7.41m\n",
      "        44           1.5918            7.28m\n",
      "        45           1.5904            7.15m\n",
      "        46           1.5891            7.02m\n",
      "        47           1.5878            6.89m\n",
      "        48           1.5863            6.76m\n",
      "        49           1.5851            6.63m\n",
      "        50           1.5839            6.50m\n",
      "        51           1.5828            6.37m\n",
      "        52           1.5814            6.24m\n",
      "        53           1.5802            6.11m\n",
      "        54           1.5791            5.99m\n",
      "        55           1.5779            5.86m\n",
      "        56           1.5767            5.72m\n",
      "        57           1.5757            5.59m\n",
      "        58           1.5744            5.46m\n",
      "        59           1.5733            5.33m\n",
      "        60           1.5722            5.20m\n",
      "        61           1.5710            5.07m\n",
      "        62           1.5700            4.94m\n",
      "        63           1.5689            4.81m\n",
      "        64           1.5677            4.68m\n",
      "        65           1.5666            4.55m\n",
      "        66           1.5656            4.41m\n",
      "        67           1.5645            4.30m\n",
      "        68           1.5636            4.17m\n",
      "        69           1.5626            4.04m\n",
      "        70           1.5615            3.91m\n",
      "        71           1.5603            3.77m\n",
      "        72           1.5594            3.64m\n",
      "        73           1.5584            3.51m\n",
      "        74           1.5574            3.38m\n",
      "        75           1.5564            3.25m\n",
      "        76           1.5556            3.12m\n",
      "        77           1.5546            2.99m\n",
      "        78           1.5536            2.86m\n",
      "        79           1.5527            2.73m\n",
      "        80           1.5519            2.60m\n",
      "        81           1.5510            2.47m\n",
      "        82           1.5501            2.34m\n",
      "        83           1.5492            2.22m\n",
      "        84           1.5482            2.09m\n",
      "        85           1.5473            1.96m\n",
      "        86           1.5465            1.82m\n",
      "        87           1.5454            1.69m\n",
      "        88           1.5446            1.56m\n",
      "        89           1.5437            1.43m\n",
      "        90           1.5429            1.30m\n",
      "        91           1.5422            1.17m\n",
      "        92           1.5414            1.04m\n",
      "        93           1.5407           54.72s\n",
      "        94           1.5399           46.90s\n",
      "        95           1.5393           39.07s\n",
      "        96           1.5385           31.25s\n",
      "        97           1.5379           23.44s\n",
      "        98           1.5370           15.62s\n",
      "        99           1.5363            7.81s\n",
      "       100           1.5355            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_iter_no_change=5, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_iter_no_change=5, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train, y_train) # на дисбалансе классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0ddae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.37      0.21      0.27      1590\n",
      "        love       0.51      0.40      0.44      1161\n",
      "     neutral       0.31      0.69      0.43      2544\n",
      "       other       0.32      0.25      0.28      2681\n",
      "     sadness       0.43      0.18      0.25      1560\n",
      "       worry       0.37      0.27      0.31      2464\n",
      "\n",
      "    accuracy                           0.35     12000\n",
      "   macro avg       0.38      0.33      0.33     12000\n",
      "weighted avg       0.37      0.35      0.33     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_y_pred = gb_clf.predict(X_test)\n",
    "print(classification_report(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0a0a795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted happiness</th>\n",
       "      <th>Predicted love</th>\n",
       "      <th>Predicted neutral</th>\n",
       "      <th>Predicted other</th>\n",
       "      <th>Predicted sadness</th>\n",
       "      <th>Predicted worry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual happiness</th>\n",
       "      <td>337</td>\n",
       "      <td>147</td>\n",
       "      <td>636</td>\n",
       "      <td>322</td>\n",
       "      <td>22</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual love</th>\n",
       "      <td>133</td>\n",
       "      <td>460</td>\n",
       "      <td>342</td>\n",
       "      <td>143</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual neutral</th>\n",
       "      <td>108</td>\n",
       "      <td>64</td>\n",
       "      <td>1766</td>\n",
       "      <td>311</td>\n",
       "      <td>37</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual other</th>\n",
       "      <td>199</td>\n",
       "      <td>112</td>\n",
       "      <td>1283</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual sadness</th>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>580</td>\n",
       "      <td>257</td>\n",
       "      <td>277</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual worry</th>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>1053</td>\n",
       "      <td>399</td>\n",
       "      <td>195</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted happiness  Predicted love  Predicted neutral  \\\n",
       "Actual happiness                  337             147                636   \n",
       "Actual love                       133             460                342   \n",
       "Actual neutral                    108              64               1766   \n",
       "Actual other                      199             112               1283   \n",
       "Actual sadness                     42              52                580   \n",
       "Actual worry                       89              73               1053   \n",
       "\n",
       "                  Predicted other  Predicted sadness  Predicted worry  \n",
       "Actual happiness              322                 22              126  \n",
       "Actual love                   143                 33               50  \n",
       "Actual neutral                311                 37              258  \n",
       "Actual other                  676                 85              326  \n",
       "Actual sadness                257                277              352  \n",
       "Actual worry                  399                195              655  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, gb_y_pred)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0dfb969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred_train = gb_clf.predict(X_train)\n",
    "y_valid5 = y_test.values.reshape(-1,1)\n",
    "y_valid_train5 = y_train.values.reshape(-1,1)\n",
    "ypred5 = gb_y_pred.reshape(-1,1)\n",
    "ypred_train5 = gb_y_pred_train.reshape(-1,1)\n",
    "y_valid5 = pd.DataFrame(y_test)\n",
    "y_valid_train5 = pd.DataFrame(y_train)\n",
    "ypred5 = pd.DataFrame(gb_y_pred)\n",
    "ypred_train5 = pd.DataFrame(gb_y_pred_train)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid5 = onehotencoder.fit_transform(y_valid5).toarray()\n",
    "y_valid_train5 = onehotencoder.fit_transform(y_valid_train5).toarray()\n",
    "ypred5 = onehotencoder.fit_transform(ypred5).toarray()\n",
    "ypred_train5 = onehotencoder.fit_transform(ypred_train5).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred5.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b17d2576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.533673366312986"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid5, ypred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdd0e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.7705           14.61m\n",
      "         2           1.7552           14.44m\n",
      "         3           1.7432           14.29m\n",
      "         4           1.7338           14.16m\n",
      "         5           1.7256           13.88m\n",
      "         6           1.7191           13.85m\n",
      "         7           1.7131           13.75m\n",
      "         8           1.7078           13.58m\n",
      "         9           1.7032           13.37m\n",
      "        10           1.6988           13.16m\n",
      "        11           1.6947           12.95m\n",
      "        12           1.6911           12.75m\n",
      "        13           1.6879           12.62m\n",
      "        14           1.6848           12.52m\n",
      "        15           1.6819           12.40m\n",
      "        16           1.6792           12.29m\n",
      "        17           1.6767           12.15m\n",
      "        18           1.6744           12.01m\n",
      "        19           1.6720           11.88m\n",
      "        20           1.6698           11.72m\n",
      "        21           1.6674           11.60m\n",
      "        22           1.6654           11.46m\n",
      "        23           1.6633           11.30m\n",
      "        24           1.6615           11.13m\n",
      "        25           1.6596           10.97m\n",
      "        26           1.6577           10.81m\n",
      "        27           1.6559           10.65m\n",
      "        28           1.6542           10.49m\n",
      "        29           1.6525           10.33m\n",
      "        30           1.6508           10.17m\n",
      "        31           1.6490           10.02m\n",
      "        32           1.6477            9.87m\n",
      "        33           1.6458            9.71m\n",
      "        34           1.6444            9.57m\n",
      "        35           1.6429            9.43m\n",
      "        36           1.6414            9.30m\n",
      "        37           1.6401            9.17m\n",
      "        38           1.6387            9.03m\n",
      "        39           1.6372            8.88m\n",
      "        40           1.6356            8.74m\n",
      "        41           1.6343            8.61m\n",
      "        42           1.6328            8.48m\n",
      "        43           1.6315            8.35m\n",
      "        44           1.6301            8.23m\n",
      "        45           1.6289            8.15m\n",
      "        46           1.6277            8.05m\n",
      "        47           1.6265            7.92m\n",
      "        48           1.6253            7.77m\n",
      "        49           1.6240            7.63m\n",
      "        50           1.6225            7.48m\n",
      "        51           1.6213            7.34m\n",
      "        52           1.6199            7.20m\n",
      "        53           1.6189            7.05m\n",
      "        54           1.6178            6.90m\n",
      "        55           1.6167            6.76m\n",
      "        56           1.6156            6.61m\n",
      "        57           1.6145            6.46m\n",
      "        58           1.6133            6.31m\n",
      "        59           1.6123            6.17m\n",
      "        60           1.6113            6.02m\n",
      "        61           1.6102            5.86m\n",
      "        62           1.6091            5.70m\n",
      "        63           1.6081            5.55m\n",
      "        64           1.6071            5.40m\n",
      "        65           1.6061            5.24m\n",
      "        66           1.6050            5.09m\n",
      "        67           1.6040            4.93m\n",
      "        68           1.6030            4.78m\n",
      "        69           1.6021            4.63m\n",
      "        70           1.6010            4.48m\n",
      "        71           1.6002            4.32m\n",
      "        72           1.5992            4.17m\n",
      "        73           1.5981            4.02m\n",
      "        74           1.5972            3.87m\n",
      "        75           1.5961            3.72m\n",
      "        76           1.5952            3.57m\n",
      "        77           1.5943            3.42m\n",
      "        78           1.5934            3.27m\n",
      "        79           1.5927            3.12m\n",
      "        80           1.5918            2.97m\n",
      "        81           1.5910            2.82m\n",
      "        82           1.5899            2.67m\n",
      "        83           1.5890            2.52m\n",
      "        84           1.5882            2.37m\n",
      "        85           1.5873            2.22m\n",
      "        86           1.5865            2.07m\n",
      "        87           1.5857            1.92m\n",
      "        88           1.5848            1.77m\n",
      "        89           1.5839            1.62m\n",
      "        90           1.5831            1.48m\n",
      "        91           1.5822            1.33m\n",
      "        92           1.5815            1.18m\n",
      "        93           1.5805            1.03m\n",
      "        94           1.5798           52.99s\n",
      "        95           1.5789           44.14s\n",
      "        96           1.5780           35.29s\n",
      "        97           1.5772           26.46s\n",
      "        98           1.5766           17.63s\n",
      "        99           1.5759            8.81s\n",
      "       100           1.5752            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_iter_no_change=5, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_iter_no_change=5, verbose=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_iter_no_change=5, verbose=10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.fit(X_train_res, y_train_res) # сбалансированные классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5c767e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_y_pred1 = gb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5719107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.32      0.35      0.33      1590\n",
      "        love       0.46      0.45      0.45      1161\n",
      "     neutral       0.33      0.51      0.40      2544\n",
      "       other       0.34      0.23      0.28      2681\n",
      "     sadness       0.35      0.29      0.32      1560\n",
      "       worry       0.36      0.29      0.32      2464\n",
      "\n",
      "    accuracy                           0.35     12000\n",
      "   macro avg       0.36      0.35      0.35     12000\n",
      "weighted avg       0.35      0.35      0.34     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gb_y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c07b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, gb_y_pred1)\n",
    "\n",
    "\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted happiness', 'Predicted love', 'Predicted neutral', \n",
    "                                                 'Predicted other', 'Predicted sadness', 'Predicted worry'],\n",
    "            index = ['Actual happiness', 'Actual love', 'Actual neutral', \n",
    "                                                 'Actual other', 'Actual sadness', 'Actual worry'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160cb36",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a22b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7007c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train) # на дисбалансе классов\n",
    "knn_y_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ae003d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.23      0.15      0.18      1590\n",
      "        love       0.42      0.24      0.31      1161\n",
      "     neutral       0.24      0.59      0.35      2544\n",
      "       other       0.25      0.14      0.18      2681\n",
      "     sadness       0.24      0.17      0.20      1560\n",
      "       worry       0.26      0.15      0.19      2464\n",
      "\n",
      "    accuracy                           0.25     12000\n",
      "   macro avg       0.27      0.24      0.23     12000\n",
      "weighted avg       0.26      0.25      0.23     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f93e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_train_pred = knn_clf.predict(X_train)\n",
    "y_valid6 = y_test.values.reshape(-1,1)\n",
    "y_valid_train6 = y_train.values.reshape(-1,1)\n",
    "ypred6 = knn_y_pred.reshape(-1,1)\n",
    "ypred_train6 = knn_y_train_pred.reshape(-1,1)\n",
    "y_valid6 = pd.DataFrame(y_test)\n",
    "y_valid_train6 = pd.DataFrame(y_train)\n",
    "ypred6 = pd.DataFrame(knn_y_pred)\n",
    "ypred_train6 = pd.DataFrame(knn_y_train_pred)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "y_valid6 = onehotencoder.fit_transform(y_valid6).toarray()\n",
    "y_valid_train6 = onehotencoder.fit_transform(y_valid_train6).toarray()\n",
    "ypred6 = onehotencoder.fit_transform(ypred6).toarray()\n",
    "ypred_train6 = onehotencoder.fit_transform(ypred_train6).toarray()\n",
    "\n",
    "\n",
    "n_classes = ypred6.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "402039a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.765927190603378"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_valid6, ypred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "321d4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_res, y_train_res) # сбалансированные классы\n",
    "knn_y_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "684e97cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.16      0.41      0.24      1590\n",
      "        love       0.17      0.58      0.26      1161\n",
      "     neutral       0.27      0.03      0.05      2544\n",
      "       other       0.27      0.01      0.02      2681\n",
      "     sadness       0.19      0.45      0.27      1560\n",
      "       worry       0.38      0.01      0.02      2464\n",
      "\n",
      "    accuracy                           0.18     12000\n",
      "   macro avg       0.24      0.25      0.14     12000\n",
      "weighted avg       0.26      0.18      0.11     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
